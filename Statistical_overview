# Import necessary libraries
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import io, re
from google.colab import files
from scipy.stats import shapiro
from statsmodels.stats.anova import AnovaRM
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from matplotlib.patches import FancyArrowPatch
import matplotlib.lines as mlines

# --------------------------
# Helper function to format parameter names for LaTeX:
# Converte gli underscore in pedici e i caret in esponenti.
def format_param(name):
    # Enclose characters following '^' in braces if not already
    name = re.sub(r"\^(?!{)(\S+)", r"^{\1}", name)
    # Enclose characters following '_' in braces if not already
    name = re.sub(r"_(?!{)(\S+)", r"_{\1}", name)
    return f"${name}$"

# --------------------------
# 1. Upload Your File
# --------------------------
print("Please upload your data file (Excel or CSV).")
uploaded = files.upload()
filename = list(uploaded.keys())[0]

# --------------------------
# 2. Read the File Based on Extension
# --------------------------
if filename.lower().endswith('.xlsx'):
    df = pd.read_excel(io.BytesIO(uploaded[filename]), header=[0, 1])
elif filename.lower().endswith('.csv'):
    df = pd.read_csv(io.StringIO(uploaded[filename].decode('utf-8')), header=[0, 1])
else:
    raise ValueError("Unsupported file format. Please upload a CSV or Excel file.")

# --------------------------
# 3. Adjust Column Names for Identifier Columns
# --------------------------
new_columns = []
for col in df.columns:
    if isinstance(col, tuple):
        if col[0] == "Parameter":
            new_columns.append("Parameter")
        elif col[0] == "Shapiro-Wilk":
            new_columns.append("Shapiro-Wilk")
        elif col[0] == "Boxplot":
            new_columns.append("Boxplot")
        elif col[0] == "PCA":
            new_columns.append("PCA")
        elif col[0] == "range":
            new_columns.append("range")
        elif col[0] == "Gruppo":
            new_columns.append("Gruppo")
        elif col[0] == "Titolo":       # Aggiunta per includere la colonna Titolo
            new_columns.append("Titolo")
        elif pd.isna(col[1]):
            new_columns.append(col[0])
        else:
            new_columns.append(col)  # Keep measurement columns as tuple
    else:
        new_columns.append(col)
df.columns = new_columns

print("Columns after adjustment:")
print(df.columns)

# --------------------------
# 4. Define Identifier and Measurement Columns
# --------------------------
id_vars = ["Parameter", "Shapiro-Wilk", "Boxplot", "PCA", "range", "Gruppo", "Titolo"]
value_vars = [col for col in df.columns if col not in id_vars]

print("Identifier columns:", id_vars)
print("Measurement columns:", value_vars)

# --------------------------
# 5. Reshape the DataFrame into Long (Tidy) Format
# --------------------------
df_long = pd.melt(
    df,
    id_vars=id_vars,
    value_vars=value_vars,
    var_name='Test_Rep',
    value_name='Value'
)
# Split the "Test_Rep" column into "Test" and "Replicate"
df_long['Test'] = df_long['Test_Rep'].apply(lambda x: x[0] if isinstance(x, tuple) else x)
df_long['Replicate'] = df_long['Test_Rep'].apply(lambda x: x[1] if isinstance(x, tuple) else None)
df_long.drop(columns=['Test_Rep'], inplace=True)

# Convert the "Value" column to numeric
df_long["Value"] = pd.to_numeric(df_long["Value"], errors="coerce")

print("\nLong-format DataFrame head:")
print(df_long.head())

# --------------------------
# 6. Compute Five-Number Summary Statistics
# --------------------------
def five_number_summary(x):
    return pd.Series({
        "Count": x.count(),
        "Min": x.min(),
        "Q1": x.quantile(0.25),
        "Median": x.median(),
        "Q3": x.quantile(0.75),
        "Max": x.max()
    })

summary_stats = (
    df_long
    .groupby(["Parameter", "Test"])["Value"]
    .apply(five_number_summary)
    .reset_index()
)

print("\nFive-number summary for each Parameter and Test:")
print(summary_stats)

# --------------------------
# 7. Run Shapiro-Wilk Normality Test When Requested
# --------------------------
def run_shapiro(group):
    flag = pd.to_numeric(group["Shapiro-Wilk"].iloc[0], errors="coerce")
    non_null = group["Value"].dropna()
    if len(non_null) < 3:
        return pd.Series({"W": None, "p_value": None, "Normality": "Not enough data", "TestPerformed": False})
    if flag == 1:
        stat, p_value = shapiro(non_null)
        conclusion = "Normal" if p_value > 0.05 else "Not normal"
        return pd.Series({"W": stat, "p_value": p_value, "Normality": conclusion, "TestPerformed": True})
    else:
        return pd.Series({"W": None, "p_value": None, "Normality": "Test not performed", "TestPerformed": False})

shapiro_results = df_long.groupby(["Parameter", "Test"]).apply(run_shapiro).reset_index()
print("\nShapiro-Wilk test results:")
print(shapiro_results)

# --------------------------
# 9. Pearson Correlation Matrix & PCA Analysis (for parameters with PCA == 1 only)
# --------------------------
selected_params = df_long[df_long["PCA"] == 1]["Parameter"].unique().tolist()
print("\nParameters selected for PCA and correlation analysis:", selected_params)

# Pivot to wide format: each row corresponds to an experiment (Test, Replicate); columns = Parameter.
df_wide = df_long.pivot_table(index=["Test", "Replicate"], columns="Parameter", values="Value")
df_wide = df_wide[selected_params]  # keep only PCA==1 parameters

# Compute the Pearson correlation matrix.
corr_matrix = df_wide.corr(method="pearson")

# --------------------------
# NEW: Compute Partial Correlation Matrix
# --------------------------
def partial_corr_matrix(df_in):
    """
    Returns the partial correlation matrix for df_in (each column a variable).
    partial_corr(i,j) = -inv_corr[i,j]/sqrt(inv_corr[i,i]*inv_corr[j,j])
    """
    # 1) Compute the correlation matrix
    corr = df_in.corr()

    # 2) Invert the correlation matrix
    #    We use np.linalg.pinv in case the matrix is not full rank; else np.linalg.inv
    corr_inv = np.linalg.pinv(corr.values)

    # 3) Build the partial correlation matrix
    p_matrix = np.zeros_like(corr_inv)
    diag_indices = np.diag_indices_from(p_matrix)
    p_matrix[diag_indices] = 1.0  # set diagonal to 1

    for i in range(corr_inv.shape[0]):
        for j in range(corr_inv.shape[1]):
            if i != j:
                p_matrix[i, j] = -corr_inv[i, j] / np.sqrt(corr_inv[i, i] * corr_inv[j, j])

    # Convert to DataFrame with same labels
    partial_corr_df = pd.DataFrame(p_matrix,
                                   index=corr.index,
                                   columns=corr.columns)
    return partial_corr_df

partial_corr_df = partial_corr_matrix(df_wide)

# Standardize the diagonal for clarity
# (In partial correlation matrices, diagonal is 1 by definition.)

# --------------------------
# Perform PCA
# --------------------------
scaler = StandardScaler()
df_wide_std = scaler.fit_transform(df_wide.dropna())  # ensure no NaNs

pca_model = PCA(n_components=2)
principal_components = pca_model.fit_transform(df_wide_std)
loadings = pca_model.components_.T  # shape: (n_features, 2)
explained_variance = pca_model.explained_variance_ratio_

# Create a DataFrame for PCA loadings.
pca_loadings_df = pd.DataFrame(loadings, index=df_wide.columns, columns=["PC1", "PC2"]).reset_index().rename(columns={"index": "Parameter"})

# Create a DataFrame for PCA scores for each observation.
# Note: We must dropna from df_wide index to align with PCA output
valid_index = df_wide.dropna().index
pca_scores_df = pd.DataFrame(principal_components, columns=["PC1", "PC2"], index=valid_index).reset_index()

# --------------------------
# 10. Save All Results to an Excel File with Multiple Sheets
# --------------------------
output_filename = "statistical_analysis_results.xlsx"
with pd.ExcelWriter(output_filename) as writer:
    summary_stats.to_excel(writer, sheet_name="Summary", index=False)
    shapiro_results.to_excel(writer, sheet_name="Shapiro-Wilk", index=False)
    corr_matrix.reset_index().to_excel(writer, sheet_name="Correlation", index=False)
    partial_corr_df.reset_index().to_excel(writer, sheet_name="PartialCorrelation", index=False)
    pca_loadings_df.to_excel(writer, sheet_name="PCA_Loadings", index=False)
    pca_scores_df.to_excel(writer, sheet_name="PCA Scores", index=False)

files.download(output_filename)

# --------------------------
# 11. Print Main Outcomes About Normality
# --------------------------
print("\nNormality Test Outcomes:")
for idx, row in shapiro_results.iterrows():
    param = row["Parameter"]
    test = row["Test"]
    if row["TestPerformed"]:
        outcome = f"Parameter '{param}' in Test '{test}': W = {row['W']:.4f}, p-value = {row['p_value']:.4f} => {row['Normality']}"
    else:
        outcome = f"Parameter '{param}' in Test '{test}': {row['Normality']}."
    print(outcome)

# --------------------------
# 12. Create a unified figure with 3 subplots (vertical):
# (A) - Pearson Correlation Heatmap
# (B) - PCA Biplot
# (C) - Partial Correlation Heatmap
# --------------------------
fig, axes = plt.subplots(3, 1, figsize=(12, 28))

## (A) Pearson Correlation Heatmap
ax1 = axes[0]
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap="coolwarm", vmin=-1, vmax=1, ax=ax1)
ax1.set_xlabel("")
ax1.set_xticklabels([format_param(label.get_text()) for label in ax1.get_xticklabels()], rotation=45, ha='right')
ax1.set_yticklabels([format_param(label.get_text()) for label in ax1.get_yticklabels()], rotation=0)
for spine in ax1.spines.values():
    spine.set_edgecolor('black')
ax1.set_title("(A) Pearson Correlation", loc='left', fontsize=20, fontweight='bold')

## (B) PCA Biplot
ax2 = axes[1]
sns.scatterplot(data=pca_scores_df, x="PC1", y="PC2", hue="Test", palette="colorblind", s=100, alpha=0.7, ax=ax2)
ax2.tick_params(axis='both', which='major', labelsize=16)

# Scale factor for arrow lengths
scaling_factor = 8
for param in pca_loadings_df["Parameter"]:
    row = pca_loadings_df[pca_loadings_df["Parameter"] == param]
    if row.empty:
        continue
    pc1 = row["PC1"].values[0]
    pc2 = row["PC2"].values[0]
    arrow_length_x = pc1 * scaling_factor
    arrow_length_y = pc2 * scaling_factor
    arrow = FancyArrowPatch(
        (0,0),
        (arrow_length_x, arrow_length_y),
        arrowstyle='-|>',
        mutation_scale=20,
        color='black',
        linewidth=2
    )
    ax2.add_patch(arrow)
    ax2.text(arrow_length_x * 1.15, arrow_length_y * 1.15, format_param(param),
             color='black', fontsize=14)

ax2.set_xlabel(f"PC1 ({explained_variance[0]*100:.1f}% var.)", fontsize=16)
ax2.set_ylabel(f"PC2 ({explained_variance[1]*100:.1f}% var.)", fontsize=16)
ax2.set_xlim(-5,5)
ax2.set_ylim(-5,5)
ax2.grid(False)
for spine in ax2.spines.values():
    spine.set_edgecolor('black')
ax2.set_title("(B) PCA Biplot", loc='left', fontsize=20, fontweight='bold')

## (C) Partial Correlation Heatmap
ax3 = axes[2]
sns.heatmap(partial_corr_df, annot=True, fmt=".2f", cmap="coolwarm", vmin=-1, vmax=1, ax=ax3)
ax3.set_xlabel("")
ax3.set_xticklabels([format_param(label.get_text()) for label in ax3.get_xticklabels()], rotation=45, ha='right')
ax3.set_yticklabels([format_param(label.get_text()) for label in ax3.get_yticklabels()], rotation=0)
for spine in ax3.spines.values():
    spine.set_edgecolor('black')
ax3.set_title("(C) Partial Correlation", loc='left', fontsize=20, fontweight='bold')

plt.tight_layout()
plt.show()

# --------------------------
# 13. Create Box Plots for flagged parameters
# (unchanged from your original, except for numbering the figure differently)
# --------------------------
df_box = df_long[df_long["Boxplot"].astype(float) == 1]

groups = ["Input", "Process"]
ncols = len(groups)
nrows = 4  # 4 boxplots per group

desired_order_input = ["A", "B", "C", "D"]
desired_order_process = ["E", "F", "G", "H"]

group_params = {}
group_titolo = {}
for g in groups:
    subset = df_box[df_box["Gruppo"] == g]
    param_titolo = subset[['Parameter', 'Titolo']].drop_duplicates()
    if g == "Input":
        param_titolo["Titolo"] = pd.Categorical(param_titolo["Titolo"], categories=desired_order_input, ordered=True)
    else:
        param_titolo["Titolo"] = pd.Categorical(param_titolo["Titolo"], categories=desired_order_process, ordered=True)
    param_titolo_sorted = param_titolo.sort_values(by='Titolo')
    group_params[g] = param_titolo_sorted['Parameter'].tolist()
    group_titolo[g] = param_titolo_sorted['Titolo'].tolist()

fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 15), squeeze=False)
for col_idx, group in enumerate(groups):
    axes[0, col_idx].set_title(group, fontsize=16, fontweight='bold', pad=20)
    params = group_params.get(group, [])
    titoli = group_titolo.get(group, [])
    for row_idx in range(nrows):
        ax = axes[row_idx, col_idx]
        if row_idx < len(params):
            param = params[row_idx]
            letter = titoli[row_idx]  # Label from the "Titolo" column
            subset = df_box[(df_box["Gruppo"] == group) & (df_box["Parameter"] == param)]
            sns.boxplot(x="Test", y="Value", data=subset, hue="Test", palette="colorblind", ax=ax)
            if ax.get_legend():
                ax.legend_.remove()
            ax.set_xlabel("")
            ax.set_ylabel(format_param(param))
            # Set y-axis limits using the "range" column if available
            r = subset["range"].iloc[0] if not subset["range"].isnull().all() else None
            if r is not None and isinstance(r, str) and ',' in r:
                try:
                    parts = r.split(',')
                    lower = float(parts[0].strip())
                    upper = float(parts[1].strip())
                    ax.set_ylim(lower, upper)
                    ticks = np.linspace(lower, upper, 6)
                    ax.set_yticks(ticks)
                except Exception as e:
                    print(f"Error converting range for parameter {param}: {e}")
            ax.text(0.01, 1.10, f"({letter})", transform=ax.transAxes,
                    fontsize=14, fontweight='bold',
                    verticalalignment='top', horizontalalignment='left',
                    color='black')
        else:
            ax.axis('off')

plt.tight_layout(rect=[0, 0, 1, 0.95])
plt.show()
